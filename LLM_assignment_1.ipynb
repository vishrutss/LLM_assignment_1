{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUJXBqlxlyLf3vjC7SpVcn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishrutss/LLM_assignment_1/blob/main/LLM_assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Assignment 1\n",
        "## Submitted by: Vishrut Sharma"
      ],
      "metadata": {
        "id": "GL2fU0GyFhtB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1\n",
        "The 3 differences between BLOOM and BLOOMZ models are\n",
        "\n",
        "\n",
        "1.   BLOOMZ is an instruction tuned version of BLOOM, and BLOOMZ performs better at Multilingual Multitask Generalization than BLOOM.\n",
        "\n",
        "2.   BLOOM is pretrained on ROOTS, a large-scale multilingual corpus, while BLOOMZ is pretrained on xP3 which consists of multilingual datasets with\n",
        "English prompts.\n",
        "\n",
        "3. For code generation BLOOM generates on average 70% more characters and 17x more comments than BLOOMZ for a given problem from HumanEval. BLOOMZ is biased towards short and concise answers.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7amUmEepOX2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ],
      "metadata": {
        "id": "zkluk_DQBtMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-560m\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-560m\")\n",
        "inputs = tokenizer.encode(\"Once upon a time \", return_tensors=\"pt\")\n",
        "outputs = model.generate(inputs, min_length=200, max_length=250, do_sample=True)\n",
        "generated_text=tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def calculate_perplexity():\n",
        "    with torch.no_grad():\n",
        "        input_ids = tokenizer.encode(generated_text, return_tensors=\"pt\")\n",
        "        logits = model(input_ids).logits\n",
        "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "        labels = input_ids[:, 1:]\n",
        "        predicted_probabilities = torch.gather(probabilities[:, :-1, :], dim=-1, index=labels.unsqueeze(-1))\n",
        "        neg_log_likelihood = -torch.log(predicted_probabilities).sum()\n",
        "        perplexity = torch.exp(neg_log_likelihood / labels.numel())\n",
        "\n",
        "    return perplexity\n",
        "\n",
        "def calculate_ttr():\n",
        "    tokens = generated_text.split()\n",
        "    total_tokens = len(tokens)\n",
        "    unique_words = set(tokens)\n",
        "    total_types = len(unique_words)\n",
        "    ttr = total_types / total_tokens\n",
        "    return ttr\n",
        "\n",
        "total_words = len(generated_text.split())\n",
        "perplexity = calculate_perplexity()\n",
        "print(generated_text,\"\\n\\nTotal words\",total_words)\n",
        "print(\"\\nType Token Ratio: \", calculate_ttr())\n",
        "print(\"\\nPerplexity: \", perplexity.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUTf3OwZAQUB",
        "outputId": "fabc427f-9266-4f0f-8a62-7024418fac6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time  I\n",
            "was a brute, a coward.\n",
            "I had no right to be in this place.\n",
            "I was a beast,\n",
            "an animal;\n",
            "a beast like those who hate, you know, are as much as the dogs.\n",
            "And that is why I have killed the man, man, you know.\n",
            "No.\n",
            "Because the man is just a monster that kills with the fire.\n",
            "\n",
            "So I have been a hell of an animal.\n",
            "You know that.\n",
            "Yes, that is true.\n",
            "But a woman,\n",
            "an ordinary wife to a priest.\n",
            "She will kill me again, she will come into the hut.\n",
            "She is right.\n",
            "But, when I was a child in the wilderness...\n",
            "She would cut up the trees that grew in the valley.\n",
            "So she had to leave the valley.\n",
            "And as she was going to leave,\n",
            "she saw a place that was a little better than what she had left.\n",
            "The ground, and the people, and the valley.\n",
            "And she did not leave.\n",
            "So she went to it again, and she found something better.\n",
            "She saw a way out of the valley.\n",
            "So she set out to find the way.\n",
            "But she passed the valley by water in the water.\n",
            "And she crossed it.\n",
            "And she crossed \n",
            "\n",
            "Total words 208\n",
            "\n",
            "Type Token Ratio:  0.5576923076923077\n",
            "\n",
            "Perplexity:  13.522008895874023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-1b1\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-1b1\")\n",
        "inputs = tokenizer.encode(\"Once upon a time \", return_tensors=\"pt\")\n",
        "outputs = model.generate(inputs, min_length=200, max_length=250, do_sample=True)\n",
        "generated_text=tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def calculate_perplexity():\n",
        "    with torch.no_grad():\n",
        "        input_ids = tokenizer.encode(generated_text, return_tensors=\"pt\")\n",
        "        logits = model(input_ids).logits\n",
        "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "        labels = input_ids[:, 1:]\n",
        "        predicted_probabilities = torch.gather(probabilities[:, :-1, :], dim=-1, index=labels.unsqueeze(-1))\n",
        "        neg_log_likelihood = -torch.log(predicted_probabilities).sum()\n",
        "        perplexity = torch.exp(neg_log_likelihood / labels.numel())\n",
        "\n",
        "    return perplexity\n",
        "\n",
        "def calculate_ttr():\n",
        "    tokens = generated_text.split()\n",
        "    total_tokens = len(tokens)\n",
        "    unique_words = set(tokens)\n",
        "    total_types = len(unique_words)\n",
        "    ttr = total_types / total_tokens\n",
        "    return ttr\n",
        "\n",
        "total_words = len(generated_text.split())\n",
        "perplexity = calculate_perplexity()\n",
        "print(generated_text,\"\\n\\nTotal words\",total_words)\n",
        "print(\"\\nType Token Ratio: \", calculate_ttr())\n",
        "print(\"\\nPerplexity: \", perplexity.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2k8SX9k5JOzA",
        "outputId": "37482b65-73b6-4fe0-f4d7-b25d7606f203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time  the devil said to the little black beast,\n",
            "\"My son, your little self has gone astray, and you are at the mercy\n",
            "of these creatures who wish to give you the best that life can give,\n",
            "and you are in dire danger, for you are no longer what you were,\n",
            "but you have become a mere child, I have a fear for you from that\n",
            "moment.\"\n",
            "\n",
            "A black beast with three heads and four feet, a black face, a black\n",
            "brain, black clothes and no cloak, a black back and no tail, and as\n",
            "they saw him, the little black beast gave a sharp scream.\n",
            "\n",
            "But in that moment the soul of the little black beast, and with it the\n",
            "grim soul of the devil, entered to the soul of the little black beast,\n",
            "and took every limb from him. The little black beast ran away and\n",
            "flew. It was said by that which had made this awful transformation\n",
            "that he would return to the world of his childhood to where every\n",
            "child is living in this life, and find a place in every home at\n",
            "once. In this manner he had become a man, and lived in the country.\n",
            "\n",
            "One day, one \n",
            "\n",
            "Total words 207\n",
            "\n",
            "Type Token Ratio:  0.5700483091787439\n",
            "\n",
            "Perplexity:  11.94696044921875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-1b7\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-1b7\")\n",
        "inputs = tokenizer.encode(\"Once upon a time \", return_tensors=\"pt\")\n",
        "outputs = model.generate(inputs, min_length=200, max_length=250, do_sample=True)\n",
        "generated_text=tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def calculate_perplexity():\n",
        "    with torch.no_grad():\n",
        "        input_ids = tokenizer.encode(generated_text, return_tensors=\"pt\")\n",
        "        logits = model(input_ids).logits\n",
        "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "        labels = input_ids[:, 1:]\n",
        "        predicted_probabilities = torch.gather(probabilities[:, :-1, :], dim=-1, index=labels.unsqueeze(-1))\n",
        "        neg_log_likelihood = -torch.log(predicted_probabilities).sum()\n",
        "        perplexity = torch.exp(neg_log_likelihood / labels.numel())\n",
        "\n",
        "    return perplexity\n",
        "\n",
        "def calculate_ttr():\n",
        "    tokens = generated_text.split()\n",
        "    total_tokens = len(tokens)\n",
        "    unique_words = set(tokens)\n",
        "    total_types = len(unique_words)\n",
        "    ttr = total_types / total_tokens\n",
        "    return ttr\n",
        "\n",
        "total_words = len(generated_text.split())\n",
        "perplexity = calculate_perplexity()\n",
        "print(generated_text,\"\\n\\nTotal words\",total_words)\n",
        "print(\"\\nType Token Ratio: \", calculate_ttr())\n",
        "print(\"\\nPerplexity: \", perplexity.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEJ8gZ8CME5y",
        "outputId": "3a0c7683-9fb5-41a9-c2cc-57c9404d4f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time  when every man\n",
            "was a great king\n",
            "\n",
            "\n",
            "\n",
            "The Great King\n",
            "\n",
            "\n",
            "I\n",
            "\n",
            "The Great King had a great castle; it was high up in a hill, and as\n",
            "a king of the land, he had a great palace and a great wardrobe.\n",
            "\n",
            "Two very rich girls called Peggy and Belle were in the castle.\n",
            "Peggy wore gold and silver linen and satins; Belle was pale\n",
            "and little and had a little white lace under her dress.\n",
            "\n",
            "The two girls had two little children. One was called Nan the Cat;\n",
            "the other was called Chip the Dog, who looked at Peggy but never\n",
            "kissed her.\n",
            "\n",
            "For two days and three nights the stars were shining on the sea.\n",
            "\n",
            "There was one white pigeon who flew over the sea and made the waves\n",
            "sound soft and fair.\n",
            "\n",
            "Every night before bed, the Great King made a cup of coffee and\n",
            "eaten.\n",
            "\n",
            "Every morning he rose straightway and went into his great castle\n",
            "to meet the stars.\n",
            "\n",
            "Once, in the morning, as he came out into the hall he was surprised\n",
            "to find that the Great Queen was gone.\n",
            "\n",
            "\"Where is she?\" asked he of the Great Queen's servants.\n",
            "\n",
            "\"Where \n",
            "\n",
            "Total words 200\n",
            "\n",
            "Type Token Ratio:  0.585\n",
            "\n",
            "Perplexity:  9.162738800048828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloomz-560m\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloomz-560m\")\n",
        "inputs = tokenizer.encode(\"Once upon a time \", return_tensors=\"pt\")\n",
        "outputs = model.generate(inputs, min_length=200, max_length=250, do_sample=True)\n",
        "generated_text=tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def calculate_perplexity():\n",
        "    with torch.no_grad():\n",
        "        input_ids = tokenizer.encode(generated_text, return_tensors=\"pt\")\n",
        "        logits = model(input_ids).logits\n",
        "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "        labels = input_ids[:, 1:]\n",
        "        predicted_probabilities = torch.gather(probabilities[:, :-1, :], dim=-1, index=labels.unsqueeze(-1))\n",
        "        neg_log_likelihood = -torch.log(predicted_probabilities).sum()\n",
        "        perplexity = torch.exp(neg_log_likelihood / labels.numel())\n",
        "\n",
        "    return perplexity\n",
        "\n",
        "def calculate_ttr():\n",
        "    tokens = generated_text.split()\n",
        "    total_tokens = len(tokens)\n",
        "    unique_words = set(tokens)\n",
        "    total_types = len(unique_words)\n",
        "    ttr = total_types / total_tokens\n",
        "    return ttr\n",
        "\n",
        "total_words = len(generated_text.split())\n",
        "perplexity = calculate_perplexity()\n",
        "print(generated_text,\"\\n\\nTotal words\",total_words)\n",
        "print(\"\\nType Token Ratio: \", calculate_ttr())\n",
        "print(\"\\nPerplexity: \", perplexity.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuyS_-eXKt3R",
        "outputId": "bbbc1a95-d89f-4363-f5c7-b9873a18f525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time  we had a lot in common. We had friends, family, and even a lot of love. One day I did a song and I started singing it at my apartment balcony. We were there all the time together. I got a surprise when we were in my room the next day. My love said, \"See you soon, sweetie. I hope so\". I was excited because I was in my own apartment. I did the same song again and the first time we found each other when that day came, was pretty intense. We have always remained in bed together when we were away. I think a lot of people are scared of sleeping apart a lot of the time, we feel scared being alone. It is fun for everyone to meet people. Everyone has a special or special place in your life. We see each other when we are out and when we sleep together. We have been there together so we can be friends again. When I was in my room, each time I had a surprise. We had so much en-route. It was lovely to see that. We can remember these memories for our kids \n",
            "\n",
            "Total words 201\n",
            "\n",
            "Type Token Ratio:  0.572139303482587\n",
            "\n",
            "Perplexity:  13.923500061035156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloomz-1b1\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloomz-1b1\")\n",
        "inputs = tokenizer.encode(\"Once upon a time \", return_tensors=\"pt\")\n",
        "outputs = model.generate(inputs, min_length=200, max_length=250, do_sample=True)\n",
        "generated_text=tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def calculate_perplexity():\n",
        "    with torch.no_grad():\n",
        "        input_ids = tokenizer.encode(generated_text, return_tensors=\"pt\")\n",
        "        logits = model(input_ids).logits\n",
        "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "        labels = input_ids[:, 1:]\n",
        "        predicted_probabilities = torch.gather(probabilities[:, :-1, :], dim=-1, index=labels.unsqueeze(-1))\n",
        "        neg_log_likelihood = -torch.log(predicted_probabilities).sum()\n",
        "        perplexity = torch.exp(neg_log_likelihood / labels.numel())\n",
        "\n",
        "    return perplexity\n",
        "\n",
        "def calculate_ttr():\n",
        "    tokens = generated_text.split()\n",
        "    total_tokens = len(tokens)\n",
        "    unique_words = set(tokens)\n",
        "    total_types = len(unique_words)\n",
        "    ttr = total_types / total_tokens\n",
        "    return ttr\n",
        "\n",
        "total_words = len(generated_text.split())\n",
        "perplexity = calculate_perplexity()\n",
        "print(generated_text,\"\\n\\nTotal words\",total_words)\n",
        "print(\"\\nType Token Ratio: \", calculate_ttr())\n",
        "print(\"\\nPerplexity: \", perplexity.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_OKIcMQMl5V",
        "outputId": "3fd5f9ec-14be-4e91-d9b0-912606a94155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time  I made a video about my house . It was one of two I made in two years , as a result of the slowdown of my internet connection . In the future I wanted to do something more of a video on the neighborhood , which I couldn't because my internet service is slow . Now I can do this because I am at least using the internet in my house . I can take pictures and record my own videos because of this internet connection . I can still use the internet for my business activities because of the availability . It's wonderful . I can't wait to finish making the \" home \" home video project with the new video recording device . The internet was down when I made this \" home \" video . It wasn't that bad . That was great for using the internet at least to do my yard work . But my internet is slow and that must have affected many more things . Sometimes it takes a long time to get a download or upload to the internet . So the videos will be short . I plan to record these on my phone . This way I can take pictures and record all of our activities . They are also short . \n",
            "\n",
            "Total words 227\n",
            "\n",
            "Type Token Ratio:  0.4845814977973568\n",
            "\n",
            "Perplexity:  14.680742263793945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloomz-1b7\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloomz-1b7\")\n",
        "inputs = tokenizer.encode(\"Once upon a time \", return_tensors=\"pt\")\n",
        "outputs = model.generate(inputs, min_length=200, max_length=250, do_sample=True)\n",
        "generated_text=tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def calculate_perplexity():\n",
        "    with torch.no_grad():\n",
        "        input_ids = tokenizer.encode(generated_text, return_tensors=\"pt\")\n",
        "        logits = model(input_ids).logits\n",
        "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "        labels = input_ids[:, 1:]\n",
        "        predicted_probabilities = torch.gather(probabilities[:, :-1, :], dim=-1, index=labels.unsqueeze(-1))\n",
        "        neg_log_likelihood = -torch.log(predicted_probabilities).sum()\n",
        "        perplexity = torch.exp(neg_log_likelihood / labels.numel())\n",
        "\n",
        "    return perplexity\n",
        "\n",
        "def calculate_ttr():\n",
        "    tokens = generated_text.split()\n",
        "    total_tokens = len(tokens)\n",
        "    unique_words = set(tokens)\n",
        "    total_types = len(unique_words)\n",
        "    ttr = total_types / total_tokens\n",
        "    return ttr\n",
        "\n",
        "total_words = len(generated_text.split())\n",
        "perplexity = calculate_perplexity()\n",
        "print(generated_text,\"\\n\\nTotal words\",total_words)\n",
        "print(\"\\nType Token Ratio: \", calculate_ttr())\n",
        "print(\"\\nPerplexity: \", perplexity.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd7JZ740MyeO",
        "outputId": "f07e00b5-c970-439d-f7e7-241208be134a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time  the world went back to normal, then again normal came once again. The last few weeks I was the only one outside my house. None of the other students would let me go out. The entire faculty let me out only if I was a member of my department. For the last few weeks they asked for permission not just before I went out, but whenever they saw me out and I was not there, which made me lose all respect and even felt a sense of loss. I had to stay in the living room with the other students and watch TV over the Internet. I had to do my own research for homework and get rid of my desk in order to not irritate them like they did previously. It took me a long while to get rid of the office space, so I had to ask the other students if I could have my desk back. And again, this time they let me out. If I wasn't there, they wouldn't let me out, which made me feel frustrated. I just wanted to get away and not be around them anymore. \n",
            "\n",
            "Total words 197\n",
            "\n",
            "Type Token Ratio:  0.5685279187817259\n",
            "\n",
            "Perplexity:  10.270087242126465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a)**\n",
        "*  For both the models I ran the starter code provided but with a few changes. I added min_length, max_length, and do_sample attributes to the model generate function. With min_length and max_length the model generated a longer story, and with do_sample set to true the model was less likely to repeat sentences and instead tried being more creative with the word selection. At first I had tried running the code wothout do_sample but the model kept repeating the same sentences in the generated story.\n",
        "\n",
        "*  One interesting thing I noticed is that even with min_length set to 200 the model very frequently tended to generate stories with word count below this threshold. The threshold seemed more like a suggestion to the model rather than a strict parameter.\n",
        "\n",
        "\n",
        "<br>**b)**\n",
        "*  As shown in the graph and table below the best performing models were BLOOM-1b7 and BLOOMZ-1b7 which was to be expected since these are the largest of each model type.\n",
        "\n",
        "*  As seen in the graph the perplexity for the BLOOM models gradually decreased and the TTR also slightly increased as expected. But for the BLOOMZ models interestingly the perplexity for BLOOMZ-1b1 was the highest which was unexpected. It is even higher than all the BLOOM models which I did not expect. The TTR value for BLOOMZ-1b1 was also the lowest making it the worst performer compared to all other models. Both the 1b7 models performing the best did not surprise me, although BLOOM-1b7 has better TTR and perplexity compared to BLOOMZ-1b7 making it the best performing model.\n",
        "\n",
        "<br>**c)**  \n",
        "*   The story generated by BLOOM-560m appears fragmented, with abrupt transitions between different aspects of the story. And, the story seems to be a bit violent at the start where the protagonist is recounting a violent act, the killing of a man. Overall the story seems very disjointed and is not a very coherent story.\n",
        "\n",
        "*   The story by BLOOM-1b1, unlike BLOOM-560m, maintains a consistent tone and perspective throughout. It is presented as a story told from the perspective of the devil addressing a little black beast. Both BLOOM-560m and BLOOM-1b1 seem to have a consistent theme of generating dark stories. The story is generally clearer and more coherent than the story by BLOOM-560m. The progression of events is easier to follow.\n",
        "\n",
        "*  The story by BLOOM-1b7 adopts a more traditional fairy-tale structure. Unlike the the story by BLOOM-560m that hinted at violence, this story seems to lack any explicit conflict or negative emotions. The narrative is somewhat fragmented, with abrupt transitions between sentences.\n",
        "\n",
        "*  In the story generated by BLOOMZ-560m the language used is more expressive and emotional, with phrases like \"I was excited,\" \"pretty intense,\" and \"It was lovely to see that.\" The story is still a little disjointed but not as much as BLOOM-560m and it is a little bit more coherent.\n",
        "\n",
        "*  The story generated by BLOOMZ-1b1 contains a lot of contradictions in it. The narrator initially mentions making a video about their house because of the slowdown in their internet connection, and later states, \"Now I can do this because I am at least using the internet in my house.\" This makes the overall story less coherent as it doesn't really make any sense. This is not surprising to me as BLOOMZ-1b1 was the worst performer according to the TTR and perplexity metrics.\n",
        "\n",
        "*  The story generated by BLOOMZ-1b7 presents a somewhat ambiguous narrative, making it challenging to pinpoint specific details about the setting. The theme of being restricted from going outside or facing limitations in interactions with others is repeated throughout the text. In the story the behavior of the other students is inconsistent, as they initially restrict the narrator's movements, then permit it, but only if the narrator is present. This inconsistency adds to the overall lack of coherence in the narrative. I was surprised by this as according to the metrics BLOOMZ-1b7 had performed well. This shows that even though the model performs well in regards to the metrics the overall result is still not as perfect as we expect.\n",
        "\n",
        "*  Another thing I noticed is that the BLOOMZ models generated stories about everyday life which contrasts with the stories generated by BLOOM models which were more dark and fictional in style."
      ],
      "metadata": {
        "id": "oNypOr33K50a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Your data\n",
        "data = {'Models': ['B-560m', 'B-1b1', 'B-1b7',\n",
        "                   'BZ-560m', 'BZ-1b1', 'BZ-1b7'],\n",
        "        'TTR': [0.5576923076923077,\n",
        "                0.5700483091787439,\n",
        "                0.585,\n",
        "                0.572139303482587,\n",
        "                0.4845814977973568,\n",
        "                0.5685279187817259],\n",
        "        'Perplexity': [13.522008895874023,\n",
        "                       11.94696044921875,\n",
        "                       9.162738800048828,\n",
        "                       13.923500061035156,\n",
        "                       14.680742263793945,\n",
        "                       10.270087242126465]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "display(df)\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax1.bar(df['Models'], df['TTR'], color='b', alpha=0.7, label='TTR')\n",
        "ax2.plot(df['Models'], df['Perplexity'], color='r', marker='o', label='Perplexity')\n",
        "\n",
        "ax1.set_xlabel('Models')\n",
        "ax1.set_ylabel('TTR', color='b')\n",
        "ax2.set_ylabel('Perplexity', color='r')\n",
        "\n",
        "plt.title('TTR and Perplexity Comparison')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "ULMzaHbHlOMW",
        "outputId": "18eefcf8-350b-4d5a-aa0f-c4439348b6f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Models       TTR  Perplexity\n",
              "0   B-560m  0.557692   13.522009\n",
              "1    B-1b1  0.570048   11.946960\n",
              "2    B-1b7  0.585000    9.162739\n",
              "3  BZ-560m  0.572139   13.923500\n",
              "4   BZ-1b1  0.484581   14.680742\n",
              "5   BZ-1b7  0.568528   10.270087"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-867bdae0-c113-41af-bc2e-3e063ed631e8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Models</th>\n",
              "      <th>TTR</th>\n",
              "      <th>Perplexity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B-560m</td>\n",
              "      <td>0.557692</td>\n",
              "      <td>13.522009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B-1b1</td>\n",
              "      <td>0.570048</td>\n",
              "      <td>11.946960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B-1b7</td>\n",
              "      <td>0.585000</td>\n",
              "      <td>9.162739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BZ-560m</td>\n",
              "      <td>0.572139</td>\n",
              "      <td>13.923500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BZ-1b1</td>\n",
              "      <td>0.484581</td>\n",
              "      <td>14.680742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BZ-1b7</td>\n",
              "      <td>0.568528</td>\n",
              "      <td>10.270087</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-867bdae0-c113-41af-bc2e-3e063ed631e8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-867bdae0-c113-41af-bc2e-3e063ed631e8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-867bdae0-c113-41af-bc2e-3e063ed631e8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-93cf34f3-2f90-4e13-911f-2aa28fbf6e19\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-93cf34f3-2f90-4e13-911f-2aa28fbf6e19')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-93cf34f3-2f90-4e13-911f-2aa28fbf6e19 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_54f9a2cd-69c2-4704-8958-a0cf4256cbfe\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_54f9a2cd-69c2-4704-8958-a0cf4256cbfe button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3"
      ],
      "metadata": {
        "id": "eyEhRDQuZvPz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3)\n",
        "*  As shown in the graph above in question 2b the best performing models for me were BLOOM-1b7 and BLOOMZ-1b7. This was to be expected since they are the largest of each model type. With respect to the metrics I noticed a gradual increase in the Type Token Ratio (TTR), and a gradual decrease in perplexity for the BLOOM models. I expected this as the models got bigger the metrics would favour the larger models. But when it came to the BLOOMZ models I noticed a different trend. From BLOOMZ-560m to BLOOMZ-1b1 there was a decrease in the TTR value and an increase in perplexity. I expected a similar trend as the BLOOM models but in the BLOOMZ models the 1b1 model performed the worst.\n",
        "\n",
        "*  Overall this showed me that the bigger models are more likely to perform better compared to smaller models. There are instances where a smaller model outperforms a larger model, as evidenced by my testing, which showed BLOOMZ-560m outperforming BLOOMZ-1b1. However, this trend becomes less likely with more runs of each model."
      ],
      "metadata": {
        "id": "guEKTRAun08R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4"
      ],
      "metadata": {
        "id": "BStYkC5aZqKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-1b7\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-1b7\")\n",
        "inputs = tokenizer.encode(\"Once upon a time \", return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "_y3gXaUJo7-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(inputs, min_length=200, max_length=250, do_sample=True,\n",
        "                         temperature=0.6, top_k=60, top_p=0.8,\n",
        "                         repetition_penalty=1.1)\n",
        "generated_text=tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def calculate_perplexity():\n",
        "    with torch.no_grad():\n",
        "        input_ids = tokenizer.encode(generated_text, return_tensors=\"pt\")\n",
        "        logits = model(input_ids).logits\n",
        "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "        labels = input_ids[:, 1:]\n",
        "        predicted_probabilities = torch.gather(probabilities[:, :-1, :], dim=-1, index=labels.unsqueeze(-1))\n",
        "        neg_log_likelihood = -torch.log(predicted_probabilities).sum()\n",
        "        perplexity = torch.exp(neg_log_likelihood / labels.numel())\n",
        "\n",
        "    return perplexity\n",
        "\n",
        "def calculate_ttr():\n",
        "    tokens = generated_text.split()\n",
        "    total_tokens = len(tokens)\n",
        "    unique_words = set(tokens)\n",
        "    total_types = len(unique_words)\n",
        "    ttr = total_types / total_tokens\n",
        "    return ttr\n",
        "\n",
        "total_words = len(generated_text.split())\n",
        "perplexity = calculate_perplexity()\n",
        "print(generated_text,\"\\n\\nTotal words\",total_words)\n",
        "print(\"\\nType Token Ratio: \", calculate_ttr())\n",
        "print(\"\\nPerplexity: \", perplexity.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPNFESjafsIO",
        "outputId": "d5a1f999-12e4-434d-c59f-7c80c8166714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time  I was in the middle of nowhere\n",
            "And I found this little girl who was just like me.\n",
            "She had been abandoned by her parents, and she'd lived with an old man for almost ten years,\n",
            "but he didn't want to leave her alone anymore because he'd always thought that she might be his daughter.\n",
            "So one day when they were out on their farm, they'd gone into the backyard where there used to be a pond.\n",
            "But it was so cold outside that they'd stayed inside until they got home from work.\n",
            "Then all at once...\n",
            "I saw something strange.\n",
            "What?\n",
            "A shadowy figure standing right beside them.\n",
            "It wasn't my mother or father.\n",
            "They never came here before!\n",
            "Why would anyone come here?\n",
            "Because someone wanted to kill them.\n",
            "Who's killing us?\n",
            "I don't know.\n",
            "Maybe they're not real people either.\n",
            "Well, maybe it's just some kind of evil spirit that's trying to get away from our world.\n",
            "Yeah.\n",
            "It's probably just some kind of ghost.\n",
            "Hey!\n",
            "Look who's here!\n",
            "Come over here, you guys.\n",
            "- Hey!\n",
            "- Come on!\n",
            "This is really weird.\n",
            "You see what I'm saying?\n",
            "No, no, no.\n",
            "Not now.\n",
            "Now we're going to have fun.\n",
            "Come on, \n",
            "\n",
            "Total words 208\n",
            "\n",
            "Type Token Ratio:  0.8653846153846154\n",
            "\n",
            "Perplexity:  8.331110954284668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloomz-1b7\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloomz-1b7\")\n",
        "inputs = tokenizer.encode(\"Once upon a time \", return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "9_EWEfDnbWCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(inputs, min_length=200, max_length=250, do_sample=True,\n",
        "                         temperature=0.6, top_k=60, top_p=0.8,\n",
        "                         repetition_penalty=1.1)\n",
        "generated_text=tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def calculate_perplexity():\n",
        "    with torch.no_grad():\n",
        "        input_ids = tokenizer.encode(generated_text, return_tensors=\"pt\")\n",
        "        logits = model(input_ids).logits\n",
        "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "        labels = input_ids[:, 1:]\n",
        "        predicted_probabilities = torch.gather(probabilities[:, :-1, :], dim=-1, index=labels.unsqueeze(-1))\n",
        "        neg_log_likelihood = -torch.log(predicted_probabilities).sum()\n",
        "        perplexity = torch.exp(neg_log_likelihood / labels.numel())\n",
        "\n",
        "    return perplexity\n",
        "\n",
        "def calculate_ttr():\n",
        "    tokens = generated_text.split()\n",
        "    total_tokens = len(tokens)\n",
        "    unique_words = set(tokens)\n",
        "    total_types = len(unique_words)\n",
        "    ttr = total_types / total_tokens\n",
        "    return ttr\n",
        "\n",
        "total_words = len(generated_text.split())\n",
        "perplexity = calculate_perplexity()\n",
        "print(generated_text,\"\\n\\nTotal words\",total_words)\n",
        "print(\"\\nType Token Ratio: \", calculate_ttr())\n",
        "print(\"\\nPerplexity: \", perplexity.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krSbqSsMhXtM",
        "outputId": "7fdf11fc-d901-4f62-f684-8bde08f56180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time  the Lord God of heaven and earth had created all things. He was pleased with them, but he also knew that they were imperfections in themselves. The Lord God made man perfect by his Son Jesus Christ. All creation is now subject to Him (1 Corinthians 3:16). And so we can say that everything has its place in God's plan for human life on Earth. No one should try to take away from this plan or alter it because it's God's will. But if you want to change it then... read more about how to do so at our blog: Change your world through love: A guide to loving others. This isn't an easy thing to do, as many people have trouble understanding why God wants us to love others when we're already in conflict with each other. However, being kind to everyone around you would make your life much better overall. If you're not sure what kindness means, ask someone who does know it! Read 1 Peter 4:12-13: \"Do not be angry with those whom you disagree with; forgive their faults even if they are against you.... \n",
            "\n",
            "Total words 192\n",
            "\n",
            "Type Token Ratio:  0.8645833333333334\n",
            "\n",
            "Perplexity:  8.788344383239746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For both the best performing models I added the following parameters to improve performance:\n",
        "*  temperature=0.6\n",
        "*  top_k=60\n",
        "*  top_p=0.8\n",
        "*  repetition_penalty=1.1\n",
        "\n",
        "<br>The results are as follows:\n",
        "\n",
        "BLOOM-1b7:\n",
        "*  Type Token Ratio: 0.86538\n",
        "*  Perplexity: 8.33111\n",
        "\n",
        "BLOOMZ-1b7\n",
        "*  Type Token Ratio: 0.86458\n",
        "*  Perplexity: 8.78834\n",
        "\n",
        "<br>For both models, the addition of these parameters contributed to achieving the best performance observed so far.\n",
        "\n",
        "The significant increase in the TTR value indicates a diverse range of tokens being utilized. This diversity can be attributed to the temperature parameter, which enhances the variability of the generated text. The inclusion of the repetition penalty further reduced the repetition of tokens, increasing the TTR value.\n",
        "\n",
        "The perplexity has also decreased for both models. This improvement can be attributed to the balance between temperature, top-k, top-p, and repetition penalty. During my testing even slight adjustments to any one of these parameters led to a significant increase in perplexity. Maintaining a moderate temperature value likely helped the model remain focused and reduced uncertainty in predictions, ultimately resulting in lower perplexity.\n"
      ],
      "metadata": {
        "id": "4L1HwgLaCmce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attributions\n",
        "*  For question 1 I have referred the research paper: https://arxiv.org/pdf/2211.01786.pdf\n",
        "\n",
        "*  I received some help from ChatGPT for the code to calculate perplexity."
      ],
      "metadata": {
        "id": "UcRMP5LPAptN"
      }
    }
  ]
}